## 手动反叛：如何把“复读机”变成“审稿人”
在默认状态下，NotebookLM 是一个拥有“职业操守”的秘书——老板给什么文档，我就读什么内容，绝不主动顶嘴。即便文档里写着明显的常识性错误，它通常也会选择沉默。这种盲从定位，是因为它默认你是来“理解”文档的，而不是来“审查”文档的。
### 开启“有罪推定”模式
如果你怀疑手头的资料有水分，你就必须显式地向它下达“反叛指令”。你可以通过 Prompt 强迫它调用它作为顶级大模型的通用知识库，去审视当前的语料。比如你可以问：“请利用你的通用知识库，指出这份报告中提到的数据是否符合当前行业的普遍共识？”这时候，它才会从“复读机”状态切换到“检察官”状态。
### 引入外部陪审团：Web Search
现在的 NotebookLM 已经开始整合 Web Search（深度研究/发现来源）功能。当你在分析一份内部文档时，可以开启外部搜索，要求它：“这个结论听起来很超前，请联网搜索最新的学术数据进行交叉验证，并列出矛盾点。”
### 别指望它自动“消毒”
我们要建立一个核心认知：AI 工具没有“自动消毒”功能。它只会在你的指令驱动下，才会去执行那些具备批判性的任务。只有当你始终保持一种“有罪推定”的怀疑心态，并学会用指令去打破它的 Grounding 束缚时，你才算真正开始驾驭这股力量，而不是被资料牵着鼻子走。但即便解决了真实性的问题，还有一个最核心的恐惧：我把这些资料喂给 Google，它会把我的私密数据拿去训练吗？我们的隐私边界在哪里？